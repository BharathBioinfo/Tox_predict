{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile ADMET Data\n",
    "The [admetSAR website provides](http://lmmd.ecust.edu.cn/admetsar1/download/) some of their training data in a bunch of text files and Excel spreadsheets. Here, we bring them each into a format where I am sure what the output means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlhub_sdk.models.datasets import TabularDataset\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle TXT files\n",
    "Some of our files are in `txt` file format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 files in txt format\n"
     ]
    }
   ],
   "source": [
    "txt_files = glob(os.path.join('..', 'databases', 'ADMET', '**', '*.txt'), recursive=True)\n",
    "print(f'Found {len(txt_files)} files in txt format')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the top of one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": Chemical name \tCAS RN\tSMILES\tEnd Points (pIGCC50,ug/L )\tSpecies\t\n",
      ": 2,4-Dichloro-6-nitroaniline\t2683434\tC1=C(C=C(C(=C1Cl)N)[N+](=O)[\n",
      ": 2,4-Dibromo-6-nitroaniline\t827236\tC1=C(C=C(C(=C1Br)N)[N+](=O)[O-\n",
      ": 6-Chloro-2,4-dinitroaniline\t3531199\tC1=C(C=C(C(=C1[N+](=O)[O-])N\n",
      ": 2-Bromo-4,6-dinitroaniline\t1817738\tC1=C(C=C(C(=C1[N+](=O)[O-])N)\n"
     ]
    }
   ],
   "source": [
    "with open(txt_files[0]) as fp:\n",
    "    for l, _ in zip(fp, range(5)):\n",
    "        print(f': {l[:64]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least one of the files is in tab-delimited format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded R_T_TPT_I. Shape: (1571, 6)\n",
      "Loaded M_CYP3A4I_I. Shape: (18561, 3)\n",
      "Loaded R_T_FHMT_I. Shape: (554, 9)\n",
      "Loaded R_A_Caco2_I. Shape: (674, 5)\n",
      "Loaded M_CYPPro_I. Shape: (11578, 11)\n",
      "Loaded WS_RM. Shape: (1708, 3)\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for f in txt_files:\n",
    "    tag = os.path.basename(f)[:-4]\n",
    "    data[tag] = pd.read_csv(f, encoding='GB18030', delimiter='\\t')\n",
    "    print(f'Loaded {tag}. Shape: {data[tag].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoding is needed because these files were saved on a Chinese computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the XLS files\n",
    "Other files are saved as Excel documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 files in Excel format\n"
     ]
    }
   ],
   "source": [
    "xls_files = glob(os.path.join('..', 'databases', 'ADMET', '**', '*.xls*'), recursive=True)\n",
    "print(f'Found {len(xls_files)} files in Excel format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded T_hERG_II. Shape: (806, 3)\n",
      "Loaded E_OCT2I_I. Shape: (907, 2)\n",
      "Loaded T_FHMT_I. Shape: (554, 4)\n",
      "Loaded A_BBB_I. Shape: (1839, 4)\n",
      "Loaded A_PgpI_I. Shape: (1273, 2)\n",
      "Loaded M_BIO_I. Shape: (1604, 3)\n",
      "Loaded A_Caco2_I. Shape: (674, 2)\n",
      "Loaded M_CYP3A4S_I. Shape: (674, 3)\n",
      "Loaded T_Carc_I. Shape: (293, 3)\n",
      "Loaded A_HIA_I. Shape: (578, 3)\n",
      "Loaded A_PgpI_II. Shape: (1275, 2)\n",
      "Loaded T_AMES_I. Shape: (8445, 4)\n",
      "Loaded T_HBT_I. Shape: (195, 4)\n",
      "Loaded T_hERG_I. Shape: (368, 3)\n",
      "Loaded M_CYP1A2I_I. Shape: (14903, 3)\n",
      "Loaded A_PgpS_I. Shape: (332, 2)\n",
      "Loaded M_CYP2D6S_I. Shape: (671, 4)\n",
      "Loaded M_CYP2D6I_I. Shape: (14741, 3)\n",
      "Loaded M_CYP2C9S_I. Shape: (673, 3)\n",
      "Loaded M_CYP2C19I_I. Shape: (14576, 3)\n",
      "Loaded T_TPT_I. Shape: (1571, 4)\n",
      "Loaded M_CYP2C9I_I. Shape: (14709, 3)\n"
     ]
    }
   ],
   "source": [
    "for f in xls_files:\n",
    "    tag = os.path.basename(f)[:-4]\n",
    "    data[tag] = pd.read_excel(f)\n",
    "    print(f'Loaded {tag}. Shape: {data[tag].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize: Define Inputs and Outputs, Add Description, etc.\n",
    "The following sections are taking the datasets and making sure that I understand what they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toxicty\n",
    "We have a few different toxicity data sources from ADMET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 9 toxicity datasets: R_T_TPT_I R_T_FHMT_I T_hERG_II T_FHMT_I T_Carc_I T_AMES_I T_HBT_I T_hERG_I T_TPT_I\n"
     ]
    }
   ],
   "source": [
    "tox_subset = dict((k, v) for k, v in data.items() if k.startswith('T') or k.startswith('R_T'))\n",
    "print(f'We have {len(tox_subset)} toxicity datasets: {\" \".join(tox_subset.keys())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translating the names (R* means regression tests). Cross-referenced with the size of the datasets present in the paper. \n",
    "Those which are ~crossed out~ are not relevant to our tasks:\n",
    "- ~R_T_TPT_I~: Toxicity for the _Tetrahymena Pyriformis_ (not relevant here)\n",
    "- ~R_T_FHMT_I~: Flathead minnow toxicity\n",
    "- T_hERG_II: Version 2 of Human Ether-a-go-go-Related Gene (hERG) Inhibition\n",
    "- ~T_FHMT_I~: Regression version of flathead minnow\n",
    "- T_Carc_I: Carcinogens (not sure exactly what this means)\n",
    "- T_AMES_I: AMES Test results\n",
    "- ~T_HBT_I~: Honey bee toxicity\n",
    "- T_hERG_I: Some other version of an HERG dataset\n",
    "- ~T_TPT_I~: Toxicity for the _Tetrahymena Pyriformis_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List out the relevant datasets and markup key details: What does the name mean? Where did it come from? Which column is the label? Which label is \"bad\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_tox = {\n",
    "    'T_hERG_I': {\n",
    "        'title': 'human Ether-à-go-go-Related Gene inhibitor, dataset 1',\n",
    "        'source': '10.1002/minf.201000159',\n",
    "        'label_col': 'Labels',\n",
    "        'toxic_class': 1\n",
    "    },\n",
    "    'T_hERG_II': {\n",
    "        'title': 'human Ether-à-go-go-Related Gene inhibitor, dataset 2',\n",
    "        'source': '10.1021/mp300023x',\n",
    "        'label_col': 'Labels',\n",
    "        'toxic_class': 1\n",
    "    },\n",
    "    'T_Carc_I': {\n",
    "        'title': 'Chemical carcinogen in rats',\n",
    "        'source': '10.1002/qsar.200860192',\n",
    "        'label_col': 'Lable',\n",
    "        'toxic_class': 1\n",
    "    },\n",
    "    'T_AMES_I': {\n",
    "        'title': 'Ames Assay',\n",
    "        'source': '10.1021/ci300400a',\n",
    "        'label_col': 'Label',\n",
    "        'toxic_class': 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the datasets and write descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, details in relevant_tox.items():\n",
    "    # Create a column where toxic-or-not is a boolean\n",
    "    dataset = data[k]\n",
    "    dataset['is_toxic'] = dataset[details['label_col']] == details['toxic_class']\n",
    "    \n",
    "    # Save it to disk as a CSV\n",
    "    out_path = os.path.join('datasets', f'{k}.csv')\n",
    "    dataset.to_csv(out_path, index=False)\n",
    "    \n",
    "    # Start the description\n",
    "    desc = TabularDataset.create_model(out_path)\n",
    "    desc.set_title(details['title'])\n",
    "    desc.set_name(k)\n",
    "    \n",
    "    # Mark the input/output columns\n",
    "    desc.mark_inputs(['SMILES'])\n",
    "    desc.mark_labels(['is_toxic'])\n",
    "        \n",
    "    # Add citations\n",
    "    desc.add_related_identifier(\"10.1021/ci300367a\", \"DOI\", \"IsDescribedBy\")\n",
    "    desc.add_related_identifier(details[\"source\"], \"DOI\", \"IsSourceOf\")\n",
    "    with open(os.path.join(os.path.dirname(out_path), f'{k}-description.json'), 'w') as fp:\n",
    "        json.dump(desc.to_dict(), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
